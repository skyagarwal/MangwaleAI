version: '3.8'

# MangwaleAI Development Environment
# Usage: docker compose -f docker-compose.dev.yml up -d

services:
  # ===========================================
  # INFRASTRUCTURE SERVICES (Always Running)
  # ===========================================
  
  postgres:
    image: postgres:16-alpine
    container_name: mangwale_dev_postgres
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=mangwale_config
      - POSTGRES_PASSWORD=config_secure_pass_2024
      - POSTGRES_DB=headless_mangwale
    volumes:
      - postgres-dev-data:/var/lib/postgresql/data
    networks:
      - mangwale-dev
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mangwale_config -d headless_mangwale"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: mangwale_dev_redis
    restart: unless-stopped
    ports:
      - "6381:6379"
    volumes:
      - redis-dev-data:/data
    networks:
      - mangwale-dev
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ===========================================
  # AI SERVICES (GPU Required)
  # ===========================================
  
  vllm:
    image: vllm/vllm-openai:v0.4.2
    container_name: mangwale_dev_vllm
    restart: unless-stopped
    ports:
      - "8002:8000"
    volumes:
      - ./backend/models/hub:/root/.cache/huggingface
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: >
      --model Qwen/Qwen2.5-7B-Instruct-AWQ
      --quantization awq
      --max-model-len 4096
      --gpu-memory-utilization 0.7
      --trust-remote-code
    networks:
      - mangwale-dev
    profiles:
      - ai

  nlu:
    image: admin-nlu:latest
    container_name: mangwale_dev_nlu
    restart: unless-stopped
    ports:
      - "7010:7010"
    volumes:
      - ./backend/models/indicbert_v3_final:/app/models/indicbert_v3_final
    environment:
      - MODEL_PATH=/app/models/indicbert_v3_final
      - PORT=7010
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - mangwale-dev
    profiles:
      - ai

  # ===========================================
  # BACKEND (NestJS) - Development Mode
  # ===========================================
  
  backend:
    image: node:20-alpine
    container_name: mangwale_dev_backend
    working_dir: /app
    command: sh -c "npm install && npm run start:dev"
    ports:
      - "3200:3200"
    volumes:
      - ./backend:/app
      - backend-node-modules:/app/node_modules
      - ./backend/logs:/app/logs
    environment:
      - NODE_ENV=development
      - PORT=3200
      - TZ=Asia/Kolkata
      
      # Database
      - DATABASE_URL=postgresql://mangwale_config:config_secure_pass_2024@mangwale_dev_postgres:5432/headless_mangwale?schema=public
      
      # Redis
      - REDIS_HOST=mangwale_dev_redis
      - REDIS_PORT=6379
      - REDIS_DB=1
      
      # AI Services
      - NLU_ENDPOINT=http://mangwale_dev_nlu:7010
      - VLLM_URL=http://mangwale_dev_vllm:8000
      - VLLM_MODEL=Qwen/Qwen2.5-7B-Instruct-AWQ
      - NLU_AI_ENABLED=true
      - LLM_MODE=hybrid
      - DEFAULT_LLM_PROVIDER=vllm
      
      # PHP Backend (if needed)
      - PHP_API_BASE_URL=${PHP_API_BASE_URL:-http://host.docker.internal:8000}
      
      # Session
      - SESSION_TTL=86400
      - OTP_TTL=600
      - OTP_LENGTH=6
      
      # Logging
      - LOG_LEVEL=debug
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - mangwale-dev
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    profiles:
      - backend

  # ===========================================
  # FRONTEND (Next.js) - Development Mode
  # ===========================================
  
  frontend:
    image: node:20-alpine
    container_name: mangwale_dev_frontend
    working_dir: /app
    command: sh -c "npm install && npm run dev"
    ports:
      - "3005:3005"
    volumes:
      - ./frontend:/app
      - frontend-node-modules:/app/node_modules
    environment:
      - NODE_ENV=development
      - NEXT_TELEMETRY_DISABLED=1
      - WATCHPACK_POLLING=true
      
      # Backend URLs
      - NEXT_PUBLIC_WS_URL=ws://localhost:3200
      - NEXT_PUBLIC_MANGWALE_AI_URL=http://localhost:3200
      - NEXT_PUBLIC_ADMIN_BACKEND_URL=http://localhost:3200
      - BACKEND_INTERNAL_URL=http://mangwale_dev_backend:3200
    networks:
      - mangwale-dev
    profiles:
      - frontend

networks:
  mangwale-dev:
    driver: bridge

volumes:
  postgres-dev-data:
  redis-dev-data:
  backend-node-modules:
  frontend-node-modules:
