# Dashboard Pages Audit - Complete Analysis

**Date**: November 18, 2025  
**Task**: Check all admin dashboard pages and identify issues

---

## ‚úÖ PAGES WORKING PROPERLY

### 1. **Flows Page** (`/admin/flows`)
- ‚úÖ Connected to real API: `http://localhost:3200/flows`
- ‚úÖ Shows 6 real flows from PostgreSQL database
- ‚úÖ Toggle/delete actions work with real API
- **NO ISSUES**

### 2. **LLM Models Page** (`/admin/llm-models`)
- ‚úÖ Shows 343 models (1 local vLLM + 342 cloud)
- ‚úÖ Local vLLM (Qwen2.5-7B-Instruct-AWQ) displayed first
- ‚úÖ Green gradient highlight for local model
- ‚úÖ Real-time data from port 8002 (vLLM) and port 3002 (cloud registry)
- **NO ISSUES**

### 3. **vLLM Settings Page** (`/admin/vllm-settings`)
- ‚úÖ NEW PAGE CREATED (just now)
- ‚úÖ Real-time GPU monitoring (RTX 3060)
- ‚úÖ VRAM, utilization, temperature display
- ‚úÖ Model configuration UI (temperature, max_tokens, top_p, top_k)
- ‚úÖ Auto-refresh every 5 seconds
- ‚úÖ Offline detection with restart instructions
- **NO ISSUES**

---

## ‚ö†Ô∏è PAGES WITH DUMMY DATA (NEED BACKEND INTEGRATION)

### 4. **Agents Page** (`/admin/agents`) - ‚úÖ FIXED (Nov 19, 2025)
**Status**: ‚úÖ Now using real API data  
**Backend**: `http://localhost:3200/agents`  
**Current**: 4 real agents from database (general, parcel, food, ecommerce)  

**API Endpoints Created**:
```typescript
GET /agents ‚Üí Returns agents grouped by module
GET /agents/:id ‚Üí Returns specific agent details
```

**Real Data Example**:
```json
{
  "id": "agent_general",
  "name": "General Agent",
  "module": "general",
  "icon": "ü§ñ",
  "status": "active",
  "model": "Qwen 2.5 7B",
  "accuracy": 48.1,  // REAL from flow runs
  "messagesHandled": 27  // REAL count
}
```

**Implementation Complete**:
- ‚úÖ Created `AgentsController` with 2 REST endpoints
- ‚úÖ Created `AgentsService` (164 lines) - groups flows by module
- ‚úÖ Registered in `AgentsModule` and deployed
- ‚úÖ Frontend updated with useEffect to fetch real data
- ‚úÖ Loading/error states implemented
- ‚è≥ Frontend needs restart to see changes

See `AGENTS_API_COMPLETE.md` for full details.

---

### 5. **Training Page** (`/admin/training`)
**Status**: Partially connected (WebSocket working, but fallback to mock data on error)  
**Current**: Shows datasets and training jobs  
**Backend Needed**:
```typescript
GET /training/datasets ‚Üí Working (port 8080)
GET /training/jobs ‚Üí Working (port 8080)
```

**Issues**:
- ‚úÖ WebSocket live updates working
- ‚ö†Ô∏è Fallback to sample data when backend unavailable
- ‚ö†Ô∏è Label Studio integration buttons need testing

**Fix Required**:
1. Ensure admin backend (port 8080) is always running
2. Remove fallback mock data (loadSampleData function)
3. Test Label Studio push/pull functionality

---

### 6. **LLM Analytics Page** (`/admin/llm-analytics`)
**Status**: Connected to port 3002 API but may show empty data  
**Current**: Usage analytics, cost trends, popular models  
**Backend**: `http://localhost:3002/llm/analytics`

**API Called**:
```typescript
llmApi.getUsageAnalytics({
  startDate: '2025-11-11',
  endDate: '2025-11-18'
})
```

**Possible Issues**:
- ‚ö†Ô∏è Port 3002 (admin backend) may not be running
- ‚ö†Ô∏è No usage data if LLM hasn't been used yet
- ‚ö†Ô∏è Date range selector works but data may be empty

**Fix Required**:
1. Verify admin backend is running on port 3002
2. Seed database with some LLM usage data for testing
3. Add "No data" state with instructions

---

### 7. **Models Registry Page** (`/admin/models`)
**Status**: Using 100% hardcoded mock data  
**Current**: Shows 5 fake models (Llama, GPT-4, Whisper, etc.)  
**Backend Needed**: None exists!

**Mock Data Example**:
```typescript
{
  id: 'model_llama_3_8b',
  name: 'Llama 3 8B',
  type: 'llm',
  provider: 'vLLM',
  status: 'active',  // FAKE
  endpoint: 'http://localhost:8000/v1'  // FAKE PORT
}
```

**Fix Required**:
1. Create `ModelsController` in mangwale-ai backend
2. Query database for registered models
3. Check model health/status in real-time
4. Update dashboard to call real API

**Note**: This page is different from `/admin/llm-models` which shows cloud LLM catalog

---

### 8. **LLM Chat Page** (`/admin/llm-chat`)
**Status**: Partially working  
**Current**: Interactive chat with model selector  
**Backend**: Calls `http://localhost:3200/llm/chat`

**Issues**:
- ‚úÖ Model selector loads 343 models successfully
- ‚ö†Ô∏è Chat endpoint may not exist at `/llm/chat`
- ‚ö†Ô∏è Error handling shows generic messages

**Test Required**:
```bash
curl -X POST http://localhost:3200/llm/chat \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"hello"}],"model":"vllm-local"}'
```

**Fix Required**:
1. Verify `/llm/chat` endpoint exists in mangwale-ai
2. Test with vLLM local model
3. Add better error messages (model offline, no API key, etc.)

---

### 9. **Dashboard Home** (`/admin/dashboard`)
**Status**: Using 100% hardcoded mock stats  
**Current**: Shows 6 stat cards + recent activity  
**Backend Needed**: **CREATED but not deployed** ‚ú®

**Mock Data Example**:
```typescript
{
  totalAgents: 9,  // FAKE
  activeModels: 5,  // FAKE
  todayMessages: 1247,  // FAKE
  todaySearches: 3892,  // FAKE
  avgResponseTime: 145,  // FAKE
  successRate: 98.5  // FAKE
}
```

**Backend API Created** (needs container rebuild):
```typescript
// ‚úÖ CREATED: src/stats/stats.module.ts
// ‚úÖ CREATED: src/stats/stats.service.ts
// ‚úÖ CREATED: src/stats/stats.controller.ts

GET /stats/dashboard ‚Üí Dashboard overview stats
GET /stats/agents ‚Üí Agent-specific statistics
GET /stats/flows ‚Üí Flow execution metrics
```

**Fix Required**:
1. Rebuild Docker container to include stats module:
   ```bash
   cd /home/ubuntu/Devs/mangwale-ai
   docker-compose build mangwale_ai_service
   docker-compose up -d mangwale_ai_service
   ```
2. Update dashboard page to call real API
3. Remove hardcoded stats

---

## üìä SUMMARY TABLE

| Page | Status | Data Source | Issues |
|------|--------|-------------|--------|
| Flows | ‚úÖ WORKING | Real API (port 3200) | None |
| LLM Models | ‚úÖ WORKING | Real APIs (8002 + 3002) | None |
| vLLM Settings | ‚úÖ NEW | Real API (port 8002) | None |
| Agents | ‚ùå FAKE | Hardcoded array | Needs backend |
| Training | ‚ö†Ô∏è PARTIAL | Admin backend (8080) | Fallback to mock |
| LLM Analytics | ‚ö†Ô∏è PARTIAL | Admin backend (3002) | May be empty |
| Models Registry | ‚ùå FAKE | Hardcoded array | Needs backend |
| LLM Chat | ‚ö†Ô∏è PARTIAL | Chat endpoint (3200) | Needs testing |
| Dashboard Home | ‚ùå FAKE | Hardcoded stats | API created, not deployed |

---

## üîß REQUIRED FIXES (Priority Order)

### Priority 1: Critical (Blocking Features)

1. **Deploy Stats API** (30 minutes)
   - Rebuild Docker container
   - Test `/stats/dashboard` endpoint
   - Update dashboard page to consume API
   - Verify real-time data updates

2. **Create Agents API** (1 hour)
   - Add `AgentsController` in mangwale-ai
   - Query flows grouped by module
   - Calculate success rates as "accuracy"
   - Update agents page

3. **Create Models Registry API** (1 hour)
   - Add `ModelsController` in mangwale-ai
   - Store model configurations in database
   - Health check integration (ping vLLM, NLU, etc.)
   - Update models page

### Priority 2: Important (Enhance Existing)

4. **Fix Training Page Fallback** (30 minutes)
   - Remove `loadSampleData()` function
   - Add proper error UI when backend is down
   - Test Label Studio integration

5. **Test LLM Chat Endpoint** (30 minutes)
   - Verify `/llm/chat` exists
   - Test with local vLLM
   - Add connection status indicator

6. **Seed LLM Analytics Data** (15 minutes)
   - Make some test LLM calls to generate usage data
   - Verify analytics page shows real charts

### Priority 3: Nice to Have

7. **Add GPU Monitoring** (2 hours)
   - Create `/system/gpu` endpoint
   - Query nvidia-smi via backend
   - Display real-time charts on vLLM settings page

8. **Real-time Dashboard Updates** (1 hour)
   - Add WebSocket to dashboard home
   - Auto-refresh stats every 10 seconds
   - Add "Live" indicator

---

## üöÄ QUICK FIX SCRIPT

To fix the most critical issues right now:

```bash
#!/bin/bash

echo "üîß FIXING DASHBOARD - QUICK DEPLOYMENT"
echo "========================================"

# 1. Rebuild mangwale-ai to include stats module
cd /home/ubuntu/Devs/mangwale-ai
echo "üì¶ Building container..."
docker-compose build mangwale_ai_service

echo "üöÄ Restarting service..."
docker-compose up -d mangwale_ai_service

echo "‚è≥ Waiting for service to start..."
sleep 15

# 2. Test stats endpoint
echo "üß™ Testing /stats/dashboard..."
curl -s http://localhost:3200/stats/dashboard | jq '.todayMessages'

# 3. Test other endpoints
echo "üß™ Testing /flows..."
curl -s http://localhost:3200/flows | jq 'length'

echo "‚úÖ DEPLOYMENT COMPLETE!"
echo ""
echo "üìä Dashboard Stats API: http://localhost:3200/stats/dashboard"
echo "ü§ñ Agents API: TODO - needs creation"
echo "üîß Models API: TODO - needs creation"
```

---

## üìù BACKEND ENDPOINTS NEEDED

### Already Exist ‚úÖ
- `GET /flows` - Flow management (WORKING)
- `GET /training/datasets` - Training datasets (port 8080)
- `GET /training/jobs` - Training jobs (port 8080)
- `GET /llm/models` - LLM catalog (port 3002)
- `GET /llm/analytics` - Usage analytics (port 3002)

### Created but Not Deployed üèóÔ∏è
- `GET /stats/dashboard` - Dashboard overview (CREATED, needs rebuild)
- `GET /stats/agents` - Agent statistics (CREATED, needs rebuild)
- `GET /stats/flows` - Flow metrics (CREATED, needs rebuild)

### Need to Create ‚ùå
- `GET /agents` - Agent list and details
- `GET /agents/:id` - Specific agent info
- `POST /llm/chat` - Chat endpoint (may exist, needs verification)
- `GET /models` - Registered models catalog
- `GET /system/gpu` - GPU monitoring data

---

## üéØ NEXT STEPS

1. **Immediate**: Rebuild container to deploy stats API
2. **Today**: Create agents and models APIs
3. **This Week**: Test all pages end-to-end with real data
4. **Future**: Add GPU monitoring and real-time updates

---

## üìö FILES CREATED

### Backend (mangwale-ai)
- ‚úÖ `src/stats/stats.module.ts` - Stats module registration
- ‚úÖ `src/stats/stats.controller.ts` - REST endpoints
- ‚úÖ `src/stats/stats.service.ts` - Business logic with Prisma
- ‚úÖ `src/app.module.ts` - Module imported

### Frontend (mangwale-unified-dashboard)
- ‚úÖ `src/app/admin/vllm-settings/page.tsx` - GPU monitoring page (NEW)
- ‚úÖ `src/lib/api/mangwale-ai.ts` - 7 flow methods added
- ‚úÖ `src/lib/api/llm.ts` - getLocalVllmInfo() method added
- ‚úÖ `src/app/admin/flows/page.tsx` - Real API integration
- ‚úÖ `src/app/admin/llm-models/page.tsx` - Local vLLM added

---

## üêõ KNOWN ISSUES

1. **Docker Container Not Rebuilt**: Stats module exists in source but not in running container
2. **Admin Backend (8080)**: May not be running consistently
3. **LLM Chat Endpoint**: Needs verification - endpoint path unclear
4. **Training Page**: Falls back to mock data silently - bad UX
5. **GPU Monitoring**: Currently uses mock/random data instead of nvidia-smi

---

**End of Audit** ‚úÖ
