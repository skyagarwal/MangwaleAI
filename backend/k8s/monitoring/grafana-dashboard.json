{
  "annotations": {
    "list": []
  },
  "description": "Mangwale AI Platform Dashboard",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 0.5 },
              { "color": "red", "value": 1 }
            ]
          },
          "unit": "s"
        }
      },
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 0 },
      "id": 1,
      "options": {
        "legend": { "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi" }
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket{app=\"mangwale-backend\"}[5m])) by (le))",
          "legendFormat": "p50"
        },
        {
          "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{app=\"mangwale-backend\"}[5m])) by (le))",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{app=\"mangwale-backend\"}[5m])) by (le))",
          "legendFormat": "p99"
        }
      ],
      "title": "API Response Latency",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "unit": "reqps"
        }
      },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 0 },
      "id": 2,
      "targets": [
        {
          "expr": "sum(rate(http_requests_total{app=\"mangwale-backend\"}[5m]))",
          "legendFormat": "Total RPS"
        },
        {
          "expr": "sum(rate(http_requests_total{app=\"mangwale-backend\",status=~\"2..\"}[5m]))",
          "legendFormat": "Success (2xx)"
        },
        {
          "expr": "sum(rate(http_requests_total{app=\"mangwale-backend\",status=~\"5..\"}[5m]))",
          "legendFormat": "Errors (5xx)"
        }
      ],
      "title": "Request Rate",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 10 },
              { "color": "red", "value": 50 }
            ]
          }
        }
      },
      "gridPos": { "h": 4, "w": 4, "x": 0, "y": 8 },
      "id": 3,
      "options": {
        "colorMode": "value",
        "graphMode": "area"
      },
      "targets": [
        {
          "expr": "vllm_pending_requests",
          "legendFormat": "Pending"
        }
      ],
      "title": "vLLM Queue",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        }
      },
      "gridPos": { "h": 4, "w": 4, "x": 4, "y": 8 },
      "id": 4,
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(vllm_request_latency_seconds_bucket[5m])) by (le))",
          "legendFormat": "p95 Latency"
        }
      ],
      "title": "LLM Latency (p95)",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "percentunit"
        }
      },
      "gridPos": { "h": 4, "w": 4, "x": 8, "y": 8 },
      "id": 5,
      "targets": [
        {
          "expr": "nvidia_gpu_memory_used_bytes / nvidia_gpu_memory_total_bytes",
          "legendFormat": "GPU Memory"
        }
      ],
      "title": "GPU Memory",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null }
            ]
          }
        }
      },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 8 },
      "id": 6,
      "targets": [
        {
          "expr": "sum(increase(conversations_started_total[1h]))",
          "legendFormat": "Started"
        },
        {
          "expr": "sum(increase(conversations_completed_total[1h]))",
          "legendFormat": "Completed"
        },
        {
          "expr": "sum(increase(conversations_abandoned_total[1h]))",
          "legendFormat": "Abandoned"
        }
      ],
      "title": "Conversations (Last Hour)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 16 },
      "id": 7,
      "targets": [
        {
          "expr": "sum by (channel) (rate(messages_received_total[5m]))",
          "legendFormat": "{{channel}}"
        }
      ],
      "title": "Messages by Channel",
      "type": "piechart"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "tokens"
        }
      },
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 16 },
      "id": 8,
      "targets": [
        {
          "expr": "sum(increase(llm_tokens_used_total[1h])) by (model)",
          "legendFormat": "{{model}}"
        }
      ],
      "title": "Token Usage by Model (Hourly)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 16 },
      "id": 9,
      "targets": [
        {
          "expr": "pg_stat_activity_count",
          "legendFormat": "Active Connections"
        },
        {
          "expr": "pg_settings_max_connections",
          "legendFormat": "Max Connections"
        }
      ],
      "title": "PostgreSQL Connections",
      "type": "timeseries"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 38,
  "tags": ["mangwale", "ai", "production"],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-6h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "browser",
  "title": "Mangwale AI Platform",
  "uid": "mangwale-main",
  "version": 1
}
