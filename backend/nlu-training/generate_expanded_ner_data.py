#!/usr/bin/env python3
"""
Generate Expanded NER Training Data - Target: 1000+ Examples
===========================================================

Current: 309 examples
Target: 1000+ examples (700 new)

Entity Types to Expand:
- FOOD: +200 examples (Hindi + English food items, generic patterns)
- STORE: +150 examples (venue types, generic store names)
- LOC: +100 examples (Nashik areas, generic locations)
- QTY: +50 examples (quantities, portions)
- PREF: +50 examples (dietary preferences, cooking instructions)
- NEW: cooking_instructions +100 examples
- NEW: delivery_time_slot +50 examples

Total New: 700 examples
"""

import json
import random
from typing import List, Dict

# ============================================================================
# FOOD PATTERNS (200 new examples)
# ============================================================================

HINDI_FOODS = [
    "misal pav", "vada pav", "pav bhaji", "chole bhature", "samosa", "kachori",
    "pani puri", "bhel puri", "sev puri", "dahi puri", "ragda pattice",
    "dabeli", "khandvi", "dhokla", "idli", "dosa", "uttapam", "medu vada",
    "masala dosa", "rava dosa", "set dosa", "upma", "poha", "sabudana khichdi",
    "thepla", "paratha", "aloo paratha", "paneer paratha", "gobi paratha",
    "roti", "naan", "butter naan", "garlic naan", "tandoori roti",
    "dal makhani", "dal fry", "rajma", "chole", "kadhi", "paneer butter masala",
    "paneer tikka", "paneer tikka masala", "malai kofta", "palak paneer",
    "aloo gobi", "bhindi masala", "baingan bharta", "dum aloo",
    "biryani", "veg biryani", "chicken biryani", "mutton biryani", "pulao",
    "fried rice", "schezwan rice", "hakka noodles", "chowmein", "manchurian",
    "momos", "veg momos", "chicken momos", "paneer momos", "fried momos",
    "pizza", "burger", "sandwich", "grilled sandwich", "club sandwich",
    "pasta", "white sauce pasta", "red sauce pasta", "penne pasta",
    "lassi", "mango lassi", "sweet lassi", "buttermilk", "chaas",
    "tea", "chai", "coffee", "cold coffee", "juice", "fresh juice",
    "gulab jamun", "rasgulla", "jalebi", "rabdi", "shrikhand", "basundi",
    "ice cream", "kulfi", "falooda", "milk shake", "chocolate shake"
]

ENGLISH_FOODS = [
    "margherita pizza", "cheese pizza", "pepperoni pizza", "veggie pizza",
    "chicken burger", "veg burger", "cheese burger", "paneer burger",
    "french fries", "potato wedges", "garlic bread", "cheesy garlic bread",
    "spring rolls", "veg spring rolls", "chicken spring rolls",
    "paneer tikka pizza", "tandoori chicken pizza", "mexican pizza",
    "grilled chicken", "tandoori chicken", "butter chicken", "chicken curry",
    "chicken biryani", "chicken fried rice", "chicken noodles",
    "egg curry", "egg biryani", "omelette", "boiled eggs",
    "fish fry", "fish curry", "prawns fry", "prawns curry",
    "mutton curry", "mutton biryani", "mutton rogan josh"
]

FOOD_NER_PATTERNS = []

# Pattern 1: Simple food mentions
for food in random.sample(HINDI_FOODS + ENGLISH_FOODS, 100):
    FOOD_NER_PATTERNS.append({
        "text": f"{food} chahiye",
        "entities": [{"start": 0, "end": len(food), "label": "FOOD", "entity": food}]
    })
    FOOD_NER_PATTERNS.append({
        "text": f"yaar {food} mangwa do",
        "entities": [{"start": 5, "end": 5+len(food), "label": "FOOD", "entity": food}]
    })

# Pattern 2: Food with quantity
QUANTITIES = ["1", "2", "3", "4", "5", "ek", "do", "teen", "char", "paanch", "half", "full"]
for food in random.sample(HINDI_FOODS, 30):
    qty = random.choice(QUANTITIES)
    text = f"{qty} {food} chahiye"
    FOOD_NER_PATTERNS.append({
        "text": text,
        "entities": [
            {"start": 0, "end": len(qty), "label": "QTY", "entity": qty},
            {"start": len(qty)+1, "end": len(qty)+1+len(food), "label": "FOOD", "entity": food}
        ]
    })

# ============================================================================
# STORE PATTERNS (150 new examples)
# ============================================================================

VENUE_TYPES = [
    "hotel", "restaurant", "cafe", "dhaba", "canteen", "mess", "food stall",
    "bakery", "sweet shop", "juice center", "chinese corner", "south indian",
    "punjabi dhaba", "maharashtrian bhojanalaya", "family restaurant",
    "fast food center", "snacks corner", "chat center", "ice cream parlor"
]

GENERIC_STORE_NAMES = [
    "sai", "ganesh", "shree", "shri", "om", "jai", "shivam", "krishna",
    "lakshmi", "durga", "mahalaxmi", "vitthal", "rama", "hanuman",
    "new", "old", "modern", "royal", "paradise", "corner", "plaza",
    "taj", "palace", "empire", "garden", "green", "blue", "red"
]

STORE_NER_PATTERNS = []

# Pattern 1: Venue type mentions
for venue in VENUE_TYPES:
    STORE_NER_PATTERNS.append({
        "text": f"{venue} se order karo",
        "entities": [{"start": 0, "end": len(venue), "label": "STORE", "entity": venue}]
    })
    STORE_NER_PATTERNS.append({
        "text": f"koi accha {venue} batao",
        "entities": [{"start": 11, "end": 11+len(venue), "label": "STORE", "entity": venue}]
    })

# Pattern 2: Generic store names + venue type
for i in range(50):
    name1 = random.choice(GENERIC_STORE_NAMES)
    name2 = random.choice(GENERIC_STORE_NAMES)
    venue = random.choice(VENUE_TYPES[:5])  # hotel, restaurant, cafe, dhaba, canteen
    store = f"{name1} {venue}"
    text = f"{store} ka number do"
    STORE_NER_PATTERNS.append({
        "text": text,
        "entities": [{"start": 0, "end": len(store), "label": "STORE", "entity": store}]
    })

# ============================================================================
# LOCATION PATTERNS (100 new examples)
# ============================================================================

NASHIK_AREAS = [
    "gangapur road", "college road", "sharanpur road", "pathardi phata",
    "indira nagar", "panchavati", "nashik road", "satpur", "ambad",
    "cidco", "dwarka", "ashok nagar", "samarth nagar", "canada corner",
    "mahatma nagar", "new cidco", "adgaon", "makhmalabad", "deolali camp",
    "mumbai naka", "malegaon", "sinnar", "dindori", "igatpuri",
    "saptashrungi", "trimbak", "kalwan", "yeola", "niphad"
]

GENERIC_LOCATIONS = [
    "station ke paas", "bus stand ke samne", "market me", "circle pe",
    "corner pe", "road pe", "main road pe", "link road pe",
    "near temple", "near hospital", "near school", "near college",
    "society me", "colony me", "layout me", "phase me"
]

LOCATION_NER_PATTERNS = []

for area in NASHIK_AREAS:
    LOCATION_NER_PATTERNS.append({
        "text": f"{area} pe delivery hoti hai kya",
        "entities": [{"start": 0, "end": len(area), "label": "LOC", "entity": area}]
    })
    LOCATION_NER_PATTERNS.append({
        "text": f"{area} ka address save karo",
        "entities": [{"start": 0, "end": len(area), "label": "LOC", "entity": area}]
    })

for loc in GENERIC_LOCATIONS:
    LOCATION_NER_PATTERNS.append({
        "text": f"delivery {loc} chahiye",
        "entities": [{"start": 9, "end": 9+len(loc), "label": "LOC", "entity": loc}]
    })

# ============================================================================
# COOKING INSTRUCTIONS (100 new examples)
# ============================================================================

COOKING_INSTRUCTIONS = [
    "extra spicy", "medium spicy", "less spicy", "no spicy", "mild",
    "extra cheese", "double cheese", "less cheese", "no cheese",
    "extra onion", "no onion", "no garlic", "no ginger",
    "well done", "medium done", "less cooked", "more cooked",
    "crispy", "soft", "hot", "warm", "room temperature",
    "extra oil", "less oil", "no oil", "ghee me banao",
    "butter nahi chahiye", "butter extra chahiye", "make it fresh",
    "tandoor me banao", "tawa pe banao", "grill karo", "fry karo",
    "boil karo", "steam karo", "roast karo", "bake karo"
]

COOKING_NER_PATTERNS = []

for instruction in COOKING_INSTRUCTIONS:
    food = random.choice(HINDI_FOODS[:20])
    text = f"{food} {instruction} chahiye"
    COOKING_NER_PATTERNS.append({
        "text": text,
        "entities": [
            {"start": 0, "end": len(food), "label": "FOOD", "entity": food},
            {"start": len(food)+1, "end": len(food)+1+len(instruction), "label": "PREF", "entity": instruction}
        ]
    })

# ============================================================================
# DELIVERY TIME SLOT (50 new examples)
# ============================================================================

TIME_SLOTS = [
    "morning me", "afternoon me", "evening me", "night me",
    "10 baje", "11 baje", "12 baje", "1 baje", "2 baje", "3 baje",
    "4 baje", "5 baje", "6 baje", "7 baje", "8 baje", "9 baje",
    "lunch time", "dinner time", "breakfast time",
    "abhi", "jaldi", "urgent", "fast delivery", "express delivery",
    "kal subah", "aaj shaam", "kal raat", "parso"
]

TIME_SLOT_NER_PATTERNS = []

for slot in TIME_SLOTS:
    text = f"delivery {slot} chahiye"
    TIME_SLOT_NER_PATTERNS.append({
        "text": text,
        "entities": [{"start": 9, "end": 9+len(slot), "label": "PREF", "entity": slot}]
    })

# ============================================================================
# NEGATIVE SAMPLES (100 examples - no entities)
# ============================================================================

NEGATIVE_SAMPLES = [
    {"text": "hello kaise ho", "entities": []},
    {"text": "kya chal raha hai", "entities": []},
    {"text": "order cancel karo", "entities": []},
    {"text": "payment nahi ho raha", "entities": []},
    {"text": "track my order", "entities": []},
    {"text": "refund chahiye", "entities": []},
    {"text": "complaint hai", "entities": []},
    {"text": "delivery boy ka number do", "entities": []},
    {"text": "kab tak aayega", "entities": []},
    {"text": "kitne time me hoga", "entities": []},
    {"text": "discount milega kya", "entities": []},
    {"text": "offer hai koi", "entities": []},
    {"text": "cart dikhao", "entities": []},
    {"text": "history check karo", "entities": []},
    {"text": "address change karna hai", "entities": []},
] * 7  # Repeat to get 105 examples

# ============================================================================
# COMBINE ALL
# ============================================================================

def generate_expanded_ner_data():
    """Generate expanded NER training data"""
    all_data = (
        FOOD_NER_PATTERNS +
        STORE_NER_PATTERNS +
        LOCATION_NER_PATTERNS +
        COOKING_NER_PATTERNS +
        TIME_SLOT_NER_PATTERNS +
        NEGATIVE_SAMPLES
    )

    # Shuffle
    random.shuffle(all_data)

    print(f"Generated {len(all_data)} new NER training examples")
    print(f"  - Food patterns: {len(FOOD_NER_PATTERNS)}")
    print(f"  - Store patterns: {len(STORE_NER_PATTERNS)}")
    print(f"  - Location patterns: {len(LOCATION_NER_PATTERNS)}")
    print(f"  - Cooking instructions: {len(COOKING_NER_PATTERNS)}")
    print(f"  - Time slots: {len(TIME_SLOT_NER_PATTERNS)}")
    print(f"  - Negative samples: {len(NEGATIVE_SAMPLES)}")

    return all_data

def main():
    # Load existing NER v4 data
    existing = []
    try:
        with open('ner_final_v4.jsonl', 'r') as f:
            existing = [json.loads(line.strip()) for line in f if line.strip()]
        print(f"\nExisting NER v4 data: {len(existing)} examples")
    except FileNotFoundError:
        print("\nNo existing NER v4 data found")

    # Generate new data
    new_data = generate_expanded_ner_data()

    # Combine (avoid duplicates)
    existing_texts = {item['text'].lower() for item in existing}
    unique_new = [item for item in new_data if item['text'].lower() not in existing_texts]

    print(f"\nUnique new examples: {len(unique_new)}")

    # Merge
    final_data = existing + unique_new
    random.shuffle(final_data)

    print(f"\nFinal dataset: {len(final_data)} examples")

    # Save
    with open('ner_final_v5_expanded.jsonl', 'w', encoding='utf-8') as f:
        for item in final_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"\nâœ… Saved to ner_final_v5_expanded.jsonl")
    print(f"Ready for NER v5 training!")

    # Entity type distribution
    entity_counts = {}
    for item in final_data:
        for ent in item.get('entities', []):
            label = ent['label']
            entity_counts[label] = entity_counts.get(label, 0) + 1

    print(f"\nEntity type distribution:")
    for label, count in sorted(entity_counts.items()):
        print(f"  {label}: {count} annotations")

    no_entity = sum(1 for item in final_data if not item.get('entities'))
    print(f"  No-entity samples: {no_entity} ({no_entity/len(final_data)*100:.1f}%)")

if __name__ == '__main__':
    main()
