import { Injectable, Logger, OnModuleInit, OnModuleDestroy } from '@nestjs/common';
import { Pool } from 'pg';
import { randomUUID } from 'crypto';

export interface SearchLog {
  query: string;
  searchType: string;
  filters?: Record<string, any>;
  resultsCount: number;
  executionTimeMs: number;
  sessionId?: string;
  userId?: string;
  platform?: string;
  lat?: number;
  lon?: number;
}

@Injectable()
export class SearchAnalyticsService implements OnModuleInit, OnModuleDestroy {
  private readonly logger = new Logger(SearchAnalyticsService.name);
  private pool: Pool;

  async onModuleInit() {
    const databaseUrl = process.env.DATABASE_URL || 
      'postgresql://mangwale_config:config_secure_pass_2024@mangwale_postgres:5432/headless_mangwale?schema=public';

    this.pool = new Pool({
      connectionString: databaseUrl,
      max: 10,
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 2000,
    });

    try {
      const client = await this.pool.connect();
      
      // Create table if not exists
      await client.query(`
        CREATE TABLE IF NOT EXISTS search_logs (
          id UUID PRIMARY KEY,
          query TEXT NOT NULL,
          search_type VARCHAR(50),
          filters JSONB,
          results_count INTEGER,
          execution_time_ms INTEGER,
          session_id VARCHAR(100),
          user_id VARCHAR(100),
          platform VARCHAR(20) DEFAULT 'unknown',
          lat DOUBLE PRECISION,
          lon DOUBLE PRECISION,
          created_at TIMESTAMP DEFAULT NOW()
        );

        CREATE INDEX IF NOT EXISTS idx_search_logs_created_at ON search_logs(created_at);
        CREATE INDEX IF NOT EXISTS idx_search_logs_query ON search_logs(query);
      `);

      // Add platform column if missing (migration for existing tables)
      await client.query(`
        ALTER TABLE search_logs ADD COLUMN IF NOT EXISTS platform VARCHAR(20) DEFAULT 'unknown'
      `).catch(() => {});

      // Create platform index (after column is guaranteed to exist)
      await client.query(`
        CREATE INDEX IF NOT EXISTS idx_search_logs_platform ON search_logs(platform)
      `).catch(() => {});

      // Add lat/lon columns for geographic search insights (migration for existing tables)
      await client.query(`
        ALTER TABLE search_logs ADD COLUMN IF NOT EXISTS lat DOUBLE PRECISION
      `).catch(() => {});
      await client.query(`
        ALTER TABLE search_logs ADD COLUMN IF NOT EXISTS lon DOUBLE PRECISION
      `).catch(() => {});
      
      client.release();
      this.logger.log('✅ Search Analytics initialized (table: search_logs)');
    } catch (error) {
      this.logger.error(`❌ Failed to initialize Search Analytics: ${error.message}`);
    }
  }

  async onModuleDestroy() {
    await this.pool.end();
  }

  async logSearch(log: SearchLog): Promise<void> {
    try {
      await this.pool.query(
        `INSERT INTO search_logs
         (id, query, search_type, filters, results_count, execution_time_ms, session_id, user_id, platform, lat, lon)
         VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)`,
        [
          randomUUID(),
          log.query,
          log.searchType,
          log.filters ? JSON.stringify(log.filters) : null,
          log.resultsCount,
          log.executionTimeMs,
          log.sessionId || null,
          log.userId || null,
          log.platform || 'unknown',
          log.lat ?? null,
          log.lon ?? null,
        ]
      );
    } catch (error) {
      this.logger.error(`Failed to log search: ${error.message}`);
    }
  }

  async getStats(days: number = 7) {
    try {
      // Total searches
      const totalRes = await this.pool.query(
        `SELECT COUNT(*) as count FROM search_logs WHERE created_at >= NOW() - INTERVAL '${days} days'`
      );
      const totalSearches = parseInt(totalRes.rows[0].count);

      // Zero results
      const zeroRes = await this.pool.query(
        `SELECT COUNT(*) as count FROM search_logs 
         WHERE results_count = 0 AND created_at >= NOW() - INTERVAL '${days} days'`
      );
      const zeroResults = parseInt(zeroRes.rows[0].count);

      // Top queries
      const topRes = await this.pool.query(
        `SELECT query, COUNT(*) as count 
         FROM search_logs 
         WHERE created_at >= NOW() - INTERVAL '${days} days'
         GROUP BY query 
         ORDER BY count DESC 
         LIMIT 10`
      );

      // Daily volume
      const volumeRes = await this.pool.query(
        `SELECT DATE(created_at) as date, COUNT(*) as count 
         FROM search_logs 
         WHERE created_at >= NOW() - INTERVAL '${days} days'
         GROUP BY DATE(created_at) 
         ORDER BY date ASC`
      );

      // Avg response time
      const timeRes = await this.pool.query(
        `SELECT AVG(execution_time_ms) as avg_time 
         FROM search_logs 
         WHERE created_at >= NOW() - INTERVAL '${days} days'`
      );
      const avgResponseTime = parseFloat(timeRes.rows[0].avg_time) || 0;

      return {
        totalSearches,
        zeroResults,
        zeroResultsRate: totalSearches > 0 ? (zeroResults / totalSearches) : 0,
        avgResponseTime: Math.round(avgResponseTime),
        topQueries: topRes.rows.map(r => ({ query: r.query, count: parseInt(r.count) })),
        dailyVolume: volumeRes.rows.map(r => ({ date: r.date, count: parseInt(r.count) })),
      };
    } catch (error) {
      this.logger.error(`Failed to get stats: ${error.message}`);
      return {
        totalSearches: 0,
        zeroResults: 0,
        zeroResultsRate: 0,
        topQueries: [],
        dailyVolume: [],
      };
    }
  }

  /**
   * Get last search for a user
   */
  async getLastSearch(userId: string): Promise<{
    query: string;
    resultsCount: number;
    filters: any;
    timestamp: Date;
  } | null> {
    try {
      const result = await this.pool.query(
        `SELECT query, results_count, filters, created_at 
         FROM search_logs 
         WHERE user_id = $1 
         ORDER BY created_at DESC 
         LIMIT 1`,
        [userId]
      );
      
      if (result.rows.length === 0) {
        return null;
      }
      
      const row = result.rows[0];
      return {
        query: row.query,
        resultsCount: row.results_count,
        filters: row.filters,
        timestamp: row.created_at,
      };
    } catch (error) {
      this.logger.error(`Failed to get last search: ${error.message}`);
      return null;
    }
  }

  /**
   * Channel breakdown - searches grouped by platform
   */
  async getChannelBreakdown(days: number = 7) {
    try {
      const result = await this.pool.query(
        `SELECT
           COALESCE(platform, 'unknown') as platform,
           COUNT(*) as searches,
           COUNT(DISTINCT COALESCE(user_id, session_id)) as unique_users,
           COUNT(*) FILTER (WHERE results_count = 0) as zero_results,
           AVG(execution_time_ms) as avg_time
         FROM search_logs
         WHERE created_at >= NOW() - INTERVAL '${days} days'
         GROUP BY COALESCE(platform, 'unknown')
         ORDER BY searches DESC`
      );

      return result.rows.map(r => {
        const searches = parseInt(r.searches);
        const zeroResults = parseInt(r.zero_results);
        return {
          platform: r.platform,
          searches,
          uniqueUsers: parseInt(r.unique_users),
          zeroResultsRate: searches > 0 ? zeroResults / searches : 0,
          avgTimeMs: Math.round(parseFloat(r.avg_time) || 0),
        };
      });
    } catch (error) {
      this.logger.error(`Failed to get channel breakdown: ${error.message}`);
      return [];
    }
  }

  /**
   * Top queries filtered by platform
   */
  async getTopQueriesByChannel(days: number = 7, platform?: string, limit: number = 20) {
    try {
      const conditions = [`created_at >= NOW() - INTERVAL '${days} days'`];
      const params: any[] = [limit];

      if (platform && platform !== 'all') {
        conditions.push(`platform = $2`);
        params.push(platform);
      }

      const result = await this.pool.query(
        `SELECT
           query,
           COUNT(*) as search_count,
           AVG(results_count) as avg_results,
           AVG(execution_time_ms) as avg_time,
           COUNT(DISTINCT COALESCE(user_id, session_id)) as unique_users,
           COALESCE(platform, 'unknown') as primary_platform
         FROM search_logs
         WHERE ${conditions.join(' AND ')}
         GROUP BY query, COALESCE(platform, 'unknown')
         ORDER BY search_count DESC
         LIMIT $1`,
        params
      );

      return result.rows.map((r, idx) => ({
        rank: idx + 1,
        query: r.query,
        searchCount: parseInt(r.search_count),
        avgResults: Math.round(parseFloat(r.avg_results) || 0),
        avgTimeMs: Math.round(parseFloat(r.avg_time) || 0),
        uniqueUsers: parseInt(r.unique_users),
        platform: r.primary_platform,
      }));
    } catch (error) {
      this.logger.error(`Failed to get top queries by channel: ${error.message}`);
      return [];
    }
  }

  /**
   * Search volume broken down by platform over time
   */
  async getVolumeByChannel(days: number = 7, granularity: string = 'day') {
    try {
      const dateTrunc = granularity === 'hour' ? `DATE_TRUNC('hour', created_at)` : `DATE(created_at)`;

      const result = await this.pool.query(
        `SELECT
           ${dateTrunc} as period,
           COALESCE(platform, 'unknown') as platform,
           COUNT(*) as search_count
         FROM search_logs
         WHERE created_at >= NOW() - INTERVAL '${days} days'
         GROUP BY ${dateTrunc}, COALESCE(platform, 'unknown')
         ORDER BY period ASC, platform`
      );

      return result.rows.map(r => ({
        period: r.period,
        platform: r.platform,
        searchCount: parseInt(r.search_count),
      }));
    } catch (error) {
      this.logger.error(`Failed to get volume by channel: ${error.message}`);
      return [];
    }
  }
}
